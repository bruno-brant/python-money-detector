{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train torchvision with our dataset:\n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "# https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# Torch enable cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"=======================================================================\")\n",
    "print(\" PyTorch version:     \", torch.__version__)\n",
    "print(\" Torchvision version: \", torchvision.__version__)\n",
    "print(\" Device:              \", device)\n",
    "print(\"=======================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [5, 10, 25, 50, 100] \t\t\t\t\t\t# We DON'T have background class...\n",
    "\"\"\"All the classes that are in the dataset\"\"\"\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\"\"\"Number of classes in the dataset\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `torch.data.Dataset` class to represent the dataset that we are using. \n",
    "\n",
    "This class implements both `__len__` and `__getitem__` to allow for consumers to obtain dataset items.\n",
    "\n",
    "* `__len__` should return the number of items in the dataset. This is the number of annotated images in the VIA json.\n",
    "* `__getitem__` returns a tuple containing the image data as well as its metadata. For now, we will return the bounding boxes of items in the dataset as well as its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import money_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import collate_fn\n",
    "from torch import utils\n",
    "from torch.utils import data\n",
    "\n",
    "from utils import collate_fn\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((1500, 2000))\n",
    "])\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset_train = CoinsDataset('../assets/dataset/TCC_MBA_Coins.json', '../assets/dataset/moedas/', transform=transform)\n",
    "dataset_test = CoinsDataset('../assets/dataset/TCC_MBA_Coins.json', '../assets/dataset/moedas/', transform=transform)\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset_train)).tolist()\n",
    "dataset_train = data.Subset(dataset_train, indices[:-50])\n",
    "dataset_test = data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f'Train dataset size: {len(dataset_train)}')\n",
    "print(f'Test dataset size: {len(dataset_test)}')\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = data.DataLoader(\n",
    "    dataset_train, batch_size=2,#)#, shuffle=True, num_workers=2)\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = data.DataLoader(\n",
    "    dataset_test, batch_size=2,#), shuffle=False, num_workers=2)\n",
    "    collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "weights = torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=weights)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = len(CLASSES)\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "# from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "# import torchvision\n",
    "\n",
    "# weights = torchvision.models.detection.MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "\n",
    "# def get_instance_segmentation_model(num_classes):\n",
    "#     # load an instance segmentation model pre-trained on COCO\n",
    "#     model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
    "#         pretrained=weights)\n",
    "\n",
    "#     # get the number of input features for the classifier\n",
    "#     in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "#     # replace the pre-trained head with a new one\n",
    "#     model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "#     # now get the number of input features for the mask classifier\n",
    "#     in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "#     hidden_layer = 256\n",
    "#     # and replace the mask predictor with a new one\n",
    "#     model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "#                                                        hidden_layer,\n",
    "#                                                        num_classes)\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the model and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# get the model using our helper function\n",
    "#model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(device: torch.device, image_list: List[torch.Tensor]):\n",
    "    idx = 0\n",
    "\n",
    "    for image in image_list:\n",
    "        idx += 1\n",
    "        print(f'moving image {idx} to device')\n",
    "        yield image.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "def train_one_epoch(model: torch.nn.Module, optimizer: torch.optim.Optimizer, data_loader: data.DataLoader[DatasetItem], device: torch.device, epoch: int, print_freq: int):\n",
    "    #metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    #metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    #header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    lr_scheduler = None\n",
    "\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = warmup_lr_scheduler(\n",
    "            optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    # metric_logger.log_every(data_loader, print_freq, header):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print('Iterating through data loader')\n",
    "    for item in data_loader:\n",
    "        # All this effort to type the goddamn thing\n",
    "        images: List[Tensor] = item[0]\n",
    "\n",
    "        print('images_type', type(images))\n",
    "        print('images', images)\n",
    "\n",
    "        targets: List[Dict[str, Tensor]] = item[1]\n",
    "\n",
    "        print('targets_type:', type(targets))\n",
    "        print('targets:', targets)\n",
    "\n",
    "        images = list(load_images(device, images))\n",
    "        targets = [{k: v.to(device) for k, v in target.items()}\n",
    "                   for target in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        print('here3')\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        #metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        # metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    # return metric_logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train it for 10 epochs\n",
    "from engine import evaluate\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader_train,\n",
    "                    device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    print(f'Epoch {epoch} finished.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dca31d16848f20992eb89f8a7472940a952ffc02113be43df95621585f721965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
