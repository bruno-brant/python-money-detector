{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from money_counter import data, engine, models, training, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 578\n",
      "Test dataset size: 30\n"
     ]
    }
   ],
   "source": [
    "data_loader_train, data_loader_test = data.get_data_loaders(os.environ['COINS_DATASET_PATH'], test_percentage=0.05)\n",
    "model, model_name = models.get_fasterrcnn_v2_pretrained()\n",
    "version_manager = models.VersionManager('../model_state')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = version_manager.get_epochs(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_149.pth\n",
      "Loaded model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_149.pth\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:58  model_time: 3.4221 (3.4221)  evaluator_time: 0.0180 (0.0180)  time: 5.8801  data: 2.2700  max mem: 3120\n",
      "Test:  [ 9/10]  eta: 0:00:02  model_time: 0.6280 (0.9057)  evaluator_time: 0.0180 (0.0176)  time: 2.9549  data: 1.9724  max mem: 3177\n",
      "Test: Total time: 0:00:29 (2.9554 s / it)\n",
      "Averaged stats: model_time: 0.6280 (0.9057)  evaluator_time: 0.0180 (0.0176)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Loading model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_148.pth\n",
      "Loaded model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_148.pth\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:32  model_time: 0.6900 (0.6900)  evaluator_time: 0.0100 (0.0100)  time: 3.2880  data: 2.5160  max mem: 3177\n",
      "Test:  [ 9/10]  eta: 0:00:02  model_time: 0.5720 (0.5928)  evaluator_time: 0.0140 (0.0159)  time: 2.5223  data: 1.8658  max mem: 3177\n",
      "Test: Total time: 0:00:25 (2.5224 s / it)\n",
      "Averaged stats: model_time: 0.5720 (0.5928)  evaluator_time: 0.0140 (0.0159)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Loading model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_147.pth\n",
      "Loaded model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_147.pth\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/10]  eta: 0:00:33  model_time: 0.6710 (0.6710)  evaluator_time: 0.0080 (0.0080)  time: 3.3430  data: 2.6190  max mem: 3177\n",
      "Test:  [ 9/10]  eta: 0:00:02  model_time: 0.6290 (0.5999)  evaluator_time: 0.0140 (0.0167)  time: 2.6145  data: 1.9525  max mem: 3177\n",
      "Test: Total time: 0:00:26 (2.6146 s / it)\n",
      "Averaged stats: model_time: 0.6290 (0.5999)  evaluator_time: 0.0140 (0.0167)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Loading model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_146.pth\n",
      "Loaded model from ../model_state/fasterrcnn_resnet50_fpn_v2/epoch_146.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m version_manager\u001b[39m.\u001b[39mload_model(model_name, model, epoch\u001b[39m=\u001b[39mepoch)\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 5\u001b[0m engine\u001b[39m.\u001b[39;49mevaluate(model, data_loader_test, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\.venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\notebooks\\..\\money_counter\\engine.py:93\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m     90\u001b[0m metric_logger \u001b[39m=\u001b[39m MetricLogger(delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m header \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTest:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m coco \u001b[39m=\u001b[39m get_coco_api_from_dataset(data_loader\u001b[39m.\u001b[39;49mdataset)\n\u001b[0;32m     94\u001b[0m iou_types \u001b[39m=\u001b[39m _get_iou_types(model)\n\u001b[0;32m     95\u001b[0m coco_evaluator \u001b[39m=\u001b[39m CocoEvaluator(coco, iou_types)\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\notebooks\\..\\money_counter\\coco_utils.py:209\u001b[0m, in \u001b[0;36mget_coco_api_from_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dataset, torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCocoDetection):\n\u001b[0;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mcoco\n\u001b[1;32m--> 209\u001b[0m \u001b[39mreturn\u001b[39;00m convert_to_coco_api(dataset)\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\notebooks\\..\\money_counter\\coco_utils.py:158\u001b[0m, in \u001b[0;36mconvert_to_coco_api\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m    154\u001b[0m categories \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m img_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ds)):\n\u001b[0;32m    156\u001b[0m     \u001b[39m# find better way to get target\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[39m# targets = ds.get_annotations(img_idx)\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     img, targets \u001b[39m=\u001b[39m ds[img_idx]\n\u001b[0;32m    159\u001b[0m     image_id \u001b[39m=\u001b[39m targets[\u001b[39m\"\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    160\u001b[0m     img_dict \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\notebooks\\..\\money_counter\\data.py:115\u001b[0m, in \u001b[0;36mCoinsDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    111\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_image(filename)\n\u001b[0;32m    112\u001b[0m target \u001b[39m=\u001b[39m to_target(\n\u001b[0;32m    113\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_images_metadata[idx], image\u001b[39m.\u001b[39msize, label_map, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename_map)\n\u001b[1;32m--> 115\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(image)\n\u001b[0;32m    117\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_metadata(target)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m image, target\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\notebooks\\..\\money_counter\\data.py:44\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, image: Image\u001b[39m.\u001b[39mImage) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Image\u001b[39m.\u001b[39mImage:\n\u001b[0;32m     43\u001b[0m     size \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39msize\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mif\u001b[39;00m size[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m size[\u001b[39m1\u001b[39m]:\n\u001b[0;32m     45\u001b[0m         image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mresize((\u001b[39m4000\u001b[39m, \u001b[39m3000\u001b[39m))\n\u001b[0;32m     46\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\source\\money-counter\\python-money-detector\\.venv\\lib\\site-packages\\PIL\\Image.py:2115\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2107\u001b[0m             \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mreduce(\u001b[39mself\u001b[39m, factor, box\u001b[39m=\u001b[39mreduce_box)\n\u001b[0;32m   2108\u001b[0m         box \u001b[39m=\u001b[39m (\n\u001b[0;32m   2109\u001b[0m             (box[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[0;32m   2110\u001b[0m             (box[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[0;32m   2111\u001b[0m             (box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[0;32m   2112\u001b[0m             (box[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[0;32m   2113\u001b[0m         )\n\u001b[1;32m-> 2115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mresize(size, resample, box))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in reversed(epochs):\n",
    "    version_manager.load_model(model_name, model, epoch=epoch)\n",
    "\n",
    "    model.to(device).eval()\n",
    "    engine.evaluate(model, data_loader_test, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dca31d16848f20992eb89f8a7472940a952ffc02113be43df95621585f721965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
